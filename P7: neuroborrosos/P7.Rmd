---
title: "Práctica 7: Sistemas neuroborrosos"
author: "Elena Marrero Castellano"
date: "5/16/2021"
output: html_document
---

En esta prác8ca final vamos a implementar el sistema ANFIS y las funciones de base radial (RBF, Radial Basis Func9on) que son los modelos neuronales más cercanos a los sistemas borrosos. Existe una carencia de implementaciones de estos modelos en Python por lo que, en esta prác8ca, se usará R.

Tenemos información del paquete que vamos a utilizar en: https://cran.r-project.org/web/packages/frbs/frbs.pdf

**1. ANFIS (ADAPTIVE NEURO-FUZZY INFERENCE SYSTEM).**

Aquí se va a usar la librería frbs desarrollada por la Universidad de Granada. Es una librería que implementa un gran número de sistemas neurodifusos entre ellos este modelo. Veamos un ejemplo ya desarrollado por esta Universidad.

```{r}
# 1. Carga de librerías.
# install.packages("frbs")
library(frbs)
```

```{r}
# 2. Carga de datos a analizar y división de los conjuntos.
data(frbsData)
data.train<-frbsData$GasFurnance.dt[1:204,] 
data.fit<-data.train[,1:2] 
data.test<-frbsData$GasFurnance.dt[205:292,1:2] 
real.val<-matrix(frbsData$GasFurnance.dt[205:292,3],ncol=1) 
rango<-matrix(c(-2.716, 2.834, 45.6, 60.5, 45.6, 60.5), nrow=2)
```

```{r}
# 3. Escogemos el método y fijamos sus parámetros de control.
metodo<-"ANFIS"
control<-list(num.labels = 5, max.iter = 100, step.size = 0.01, type.mf = 3, name = "GasFur")
```


```{r}
# 4. Generamos el sistema borroso.
object <- frbs.learn(data.train, rango, metodo, control)
```

```{r}
# 5. Ajustamos el modelo.
res.fit <- predict(object, data.fit)
```

```{r}
# 6. Predicción del modelo.
res.test <- predict(object, data.test)
```

```{r}
# 7. Cálculo de los errores.
y.pred <- res.test
y.real <- real.val
bench <- cbind(y.pred, y.real)
colnames(bench) <- c("pred. val.", "real. val.") 
print("Comparación entre ANFIS Vs Valores Reales en el Gas Furnace Data Set")
print(bench)
errores <- (y.real-y.pred)
MSE <- mean(errores ^2)
RMSE <- sqrt(mean(errores ^2))
err <- c(MSE, RMSE)
names(err) <- c("MSE", "RMSE")
print(err)
```

```{r}
# 8. Representación de la señal deseada frente a la obtenida.
op <- par(mfrow = c(2, 1))
x1 <- seq(from = 1, to = nrow(res.fit))
result.fit <- cbind(data.train[, 3], res.fit)
plot(x1, result.fit[, 1], col="red", main = "Gas Furnance: Etapa de ajuste (datos entrenamiento(red) Vs Simulado(blue))", type = "l", ylab = "CO2")
lines(x1, result.fit[, 2], col="blue")
result.test <- cbind(real.val, res.test)

x2 <- seq(from = 1, to = nrow(result.test))
plot(x2, result.test[, 1], col="red", main = "Gas Furnance: Etapa de predicción (Datos reales(red) Vs Simulaciones(blue))", type = "l", ylab = "CO2")
lines(x2, result.test[, 2], col="blue", type = "l")
par(op)
```


**EJERCICIO 1.1 Repite el ejercicio considerando la otra serie que contiene la lista frbsData (serie de MacKey-Glass).**

La serie temporal caótica de Mackey-Glass se define mediante la siguiente ecuación diferencial retardada:

$$\frac{d_x (t)}{d_t} = \frac{a * x (t - T) }{(1 + x (t - τ) ^ 10)} - b * x (t)$$

Para este conjunto de datos, generamos 1000 muestras, con los siguientes parámetros de entrada: a = 0.2; b = 0.1; T = 17; $x_0$ = 1.2; $d_t$ = 1;

El conjunto de datos está incrustado de la siguiente manera: variables de entrada: x (t - 18) , x (t - 12) , x (t - 6) , x (t) y variable de salida: x (t + 6)

```{r}
# 1. Carga de librerías.
# install.packages("frbs")
library(frbs)
```

```{r}
# 2. Carga de datos a analizar y división de los conjuntos.
data(frbsData)
data.train <- frbsData$MackeyGlass1000.dt[1: 500, ]
data.fit <- data.train[, 1 : 4]
data.test <- frbsData$MackeyGlass1000.dt[501 : 1000, 1 : 4]
real.val <- matrix(frbsData$MackeyGlass1000.dt[501 : 1000, 5], ncol = 1)
rango <- matrix(c(0.43462, 1.3105, 0.43462, 1.3105, 0.43462, 1.3105, 0.43462, 1.3105, 0.43462, 1.3105), nrow=2)
```

```{r}
# 3. Escogemos el método y fijamos sus parámetros de control.
metodo <- "ANFIS"
control <- list(num.labels = 5, max.iter = 100, step.size = 0.01, type.mf = 3, name = "MacKey-Glass")
```


```{r}
# 4. Generamos el sistema borroso.
object <- frbs.learn(data.train, rango, metodo, control)
```

```{r}
# 5. Ajustamos el modelo.
res.fit <- predict(object, data.fit)
```

```{r}
# 6. Predicción del modelo.
res.test <- predict(object, data.test)
```

```{r}
# 7. Cálculo de los errores.
y.pred <- res.test
y.real <- real.val
bench <- cbind(y.pred, y.real)
colnames(bench) <- c("pred. val.", "real. val.") 
print("Comparación entre ANFIS Vs Valores Reales en el Gas Furnace Data Set")
print(bench)
# El valor de pred. val. no varia mientras que el real. val. va variando.

errores <- (y.real-y.pred)
MSE <- mean(errores ^2)
RMSE <- sqrt(mean(errores ^2))
err <- c(MSE, RMSE)
names(err) <- c("MSE", "RMSE")
print(err)
```

```{r}
# 8. Representación de la señal deseada frente a la obtenida.
op <- par(mfrow = c(2, 1))
x1 <- seq(from = 1, to = nrow(res.fit))
result.fit <- cbind(data.train[, 5], res.fit)
plot(x1, result.fit[, 1], col="red", main = "Mackey Glass: Fase de adaptación (los datos de entrenamiento (rojo) Vs Sim. Resultado (azul))", type = "l", ylab = "MG")
lines(x1, result.fit[, 2], col="blue")


result.test <- cbind(real.val, res.test)
x2 <- seq(from = 1, to = nrow(result.test))
plot(x2, result.test[, 1], col="red", main = "Mackey Glass: Fase de predicción (el resultado de datos reales (rojo) Vs Sim. (Azul))", type = "l", ylab = "MG")
lines(x2, result.test[, 2], col="blue", type = "l")
par(op)
```

**EJERCICIO 1.2 Cambia los parámetros del ANFIS y comprueba su funcionamiento.**

```{r}
# 1. Carga de librerías.
# install.packages("frbs")
library(frbs)
```

```{r}
# 2. Carga de datos a analizar y división de los conjuntos.
data(frbsData)
data.train <- frbsData$MackeyGlass1000.dt[1: 500, ]
data.fit <- data.train[, 1 : 4]
data.test <- frbsData$MackeyGlass1000.dt[501 : 1000, 1 : 4]
real.val <- matrix(frbsData$MackeyGlass1000.dt[501 : 1000, 5], ncol = 1)
rango <- matrix(c(0.43462, 1.3105, 0.43462, 1.3105, 0.43462, 1.3105, 0.43462, 1.3105, 0.43462, 1.3105), nrow=2)
```

```{r}
# 3. Escogemos el método y fijamos sus parámetros de control.
metodo <- "ANFIS"
control0 <- list(num.labels = 5, max.iter = 100, step.size = 0.01, type.mf = 3, name = "GasFur")
control1 <- list(num.labels = 5, max.iter = 50, step.size = 0.01, type.mf = 3, name = "GasFur")
control2 <- list(num.labels = 5, max.iter = 100, step.size = 0.01, type.tnorm = "MIN", type.snorm = "MAX", type.implication.func = "ZADEH", name = "MG1000")
control3 <- list(num.labels = 5, max.iter = 50, step.size = 0.01, type.tnorm = "MIN", type.snorm = "MAX", type.implication.func = "ZADEH", name = "MG1000")
```


```{r}
# 4. Generamos el sistema borroso.
object0 <- frbs.learn(data.train, rango, metodo, control0)
object1 <- frbs.learn(data.train, rango, metodo, control1)
object2 <- frbs.learn(data.train, rango, metodo, control2)
object3 <- frbs.learn(data.train, rango, metodo, control3)
```

```{r}
# 5. Ajustamos el modelo.
res.fit0 <- predict(object0, data.fit)
res.fit1 <- predict(object1, data.fit)
res.fit2 <- predict(object2, data.fit)
res.fit3 <- predict(object3, data.fit)
```

```{r}
# 6. Predicción del modelo.
res.test0 <- predict(object0, data.test)
res.test1 <- predict(object1, data.test)
res.test2 <- predict(object2, data.test)
res.test3 <- predict(object3, data.test)
```

```{r}
# 7. Cálculo de los errores.
y.pred0 <- res.test0
y.pred1 <- res.test1
y.pred2 <- res.test2
y.pred3 <- res.test3

y.real0 <- real.val
y.real1 <- real.val
y.real2 <- real.val
y.real3 <- real.val

bench0 <- cbind(y.pred0, y.real0)
bench1 <- cbind(y.pred1, y.real1)
bench2 <- cbind(y.pred2, y.real2)
bench3 <- cbind(y.pred3, y.real3)

colnames(bench0) <- c("pred. val.0", "real. val.0") 
colnames(bench1) <- c("pred. val.1", "real. val.1") 
colnames(bench2) <- c("pred. val.2", "real. val.2") 
colnames(bench3) <- c("pred. val.3", "real. val.3") 

# print("Comparación entre ANFIS Vs Valores Reales en el Gas Furnace Data Set")
# print(bench)

errores0 <- (y.real0-y.pred0)
errores1 <- (y.real1-y.pred1)
errores2 <- (y.real2-y.pred2)
errores3 <- (y.real3-y.pred3)

MSE0 <- mean(errores0 ^2)
MSE1 <- mean(errores1 ^2)
MSE2 <- mean(errores2 ^2)
MSE3 <- mean(errores3 ^2)

RMSE0 <- sqrt(mean(errores0 ^2))
RMSE1 <- sqrt(mean(errores1 ^2))
RMSE2 <- sqrt(mean(errores2 ^2))
RMSE3 <- sqrt(mean(errores3 ^2))

err0 <- c(MSE0, RMSE0)
err1 <- c(MSE1, RMSE1)
err2 <- c(MSE2, RMSE2)
err3 <- c(MSE3, RMSE3)

names(err0) <- c("MSE0", "RMSE0")
names(err1) <- c("MSE1", "RMSE1")
names(err2) <- c("MSE2", "RMSE2")
names(err3) <- c("MSE3", "RMSE3")

head(err0)
head(err1)
head(err2)
head(err3)
```

```{r}
# 8. Representación de la señal deseada frente a la obtenida.
par(mfrow = c(2, 2))
x0 <- seq(from = 1, to = nrow(res.fit0))
result.fit0 <- cbind(data.train[, 5], res.fit0)
plot(x0, result.fit0[, 1], col="red", main = "Mackey Glass: Fase de adaptación (los datos de entrenamiento (rojo) Vs Sim. Resultado (azul))", type = "l", ylab = "MG")
lines(x0, result.fit0[, 2], col="blue")

x1 <- seq(from = 1, to = nrow(res.fit1))
result.fit1 <- cbind(data.train[, 5], res.fit1)
plot(x1, result.fit1[, 1], col="red", main = "Mackey Glass: Fase de adaptación (los datos de entrenamiento (rojo) Vs Sim. Resultado (azul))", type = "l", ylab = "MG")
lines(x1, result.fit1[, 2], col="blue")

x2 <- seq(from = 1, to = nrow(res.fit2))
result.fit2 <- cbind(data.train[, 5], res.fit2)
plot(x2, result.fit2[, 1], col="red", main = "Mackey Glass: Fase de adaptación (los datos de entrenamiento (rojo) Vs Sim. Resultado (azul))", type = "l", ylab = "MG")
lines(x2, result.fit2[, 2], col="blue")

x3 <- seq(from = 1, to = nrow(res.fit3))
result.fit3 <- cbind(data.train[, 5], res.fit3)
plot(x3, result.fit3[, 1], col="red", main = "Mackey Glass: Fase de adaptación (los datos de entrenamiento (rojo) Vs Sim. Resultado (azul))", type = "l", ylab = "MG")
lines(x3, result.fit3[, 2], col="blue")

par(mfrow = c(2, 2))
result.test0 <- cbind(real.val, res.test0)
x2.0 <- seq(from = 1, to = nrow(result.test0))
plot(x2.0, result.test0[, 1], col="red", main = "Mackey Glass: Fase de predicción (el resultado de datos reales (rojo) Vs Sim. (Azul))", type = "l", ylab = "MG")
lines(x2.0, result.test0[, 2], col="blue", type = "l")

result.test1 <- cbind(real.val, res.test1)
x2.1 <- seq(from = 1, to = nrow(result.test1))
plot(x2.1, result.test1[, 1], col="red", main = "Mackey Glass: Fase de predicción (el resultado de datos reales (rojo) Vs Sim. (Azul))", type = "l", ylab = "MG")
lines(x2.1, result.test1[, 2], col="blue", type = "l")

result.test2 <- cbind(real.val, res.test2)
x2.2 <- seq(from = 1, to = nrow(result.test2))
plot(x2.2, result.test2[, 1], col="red", main = "Mackey Glass: Fase de predicción (el resultado de datos reales (rojo) Vs Sim. (Azul))", type = "l", ylab = "MG")
lines(x2.2, result.test2[, 2], col="blue", type = "l")

result.test3 <- cbind(real.val, res.test3)
x2.3 <- seq(from = 1, to = nrow(result.test3))
plot(x2.3, result.test3[, 1], col="red", main = "Mackey Glass: Fase de predicción (el resultado de datos reales (rojo) Vs Sim. (Azul))", type = "l", ylab = "MG")
lines(x2.3, result.test3[, 2], col="blue", type = "l")

```


**Ejercicio 2. Funciones de base radial (RBF).**

En este apartado vamos a implementar, desde cero, una función de base radial muy sencilla. El problema a resolver es un problema de modelización unidimensional del tipo y=f(x). En este caso la estructura que se tiene es la siguiente:

```{r}
# install.packages("rdetools")
library(rdetools)
library(tidyr)

# Escogemos alpha y el número funciones de base radial
alpha = 0.12
L = 15
M = 50

# Genera 50 puntos de la variable de entrada x mediante una distribución uniforme entre -5 y 5.
x <- seq(-5, 5, length.out = 50)
d = sinc(x) # deseada

# Tomamos centros al azar
centros = sample(x, L)

# Calculamos la distancia entre los centros
dist_max = max(centros)- min(centros)

# Obtenemos la varianza
var =  (dist_max/(sqrt(2*M)))**2

# Definimos las variables a utilizar 
Nepochs = 1000
peso = rep(0,L) # Inicializamos todos los pesos a 0
epocas <- seq(1,Nepochs)

phi <- function(x,c,v){
  exp(-((x-c)**2)/(2*v**2))
}

s <- rep(0,M)
error_l = rep(0,M)
MSE = c()

# Bucle de épocas
for (e in 1:Nepochs){
  factor <- rep(0,L)
  
  # Bucle de patrones 
  for (i in 1:M){
    
    # Caculamos s_t
    salida=peso*exp(-((x[i]-centros)^2)/(2*var^2))
    s[i]=sum(salida)

    # Calculamos e_t
    error = d[i] - s[i]
    error_l[i] = error
    
    # Calculamos el factor
    fac = error * phi(x[i], centros, var)
    factor=factor + fac

 
  }# Fin del bucle de patrones
  
  
  # Actualizamos w_k en cada época (1:L)
  peso = peso + 2*alpha / M * factor
  
  # Calculamos el error cuadrático medio
  MSE = append(MSE, sum(error_l^2)/M)
  
}# Fin del bucle de épocas

plot(d, col="red", type='l')
lines(s, col="blue")
```

- Comprueba el funcionamiento de tu implementación representando el MSE (error cuadrático medio) por época (cuando le pasas al modelo todos los patrones). Aquí actualizaremos en modo batch los parámetros (en nuestro caso los coeficientes w).

```{r}
plot(epocas, MSE, col="red", type='l')
```

- La siguiente modificación, también sencilla, es aplicar un algoritmo de clustering para obtener los centros iniciales. Implementa dicha modificación en tu algoritmo planteado.

```{r}

```

- Finalmente, (y esto es un plus) se podría plantear la regla delta para todos los parámetros del modelo (coeficientes, centros y varianzas).
















